{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anonomaly detection with k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use k-means clustering to detect anomalies in unlabelled data. i.e. We dont know what anomalies looks like beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from the daily measures of sensors in a urban waste water treatment plant. The objective is to classify the operational state of the plant in order to predict faults through the state variables of the plant at each of the stages of the treatment process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='water.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in the data are as follows:\n",
    "\n",
    "| Column   | Description                                                          |\n",
    "|----------|----------------------------------------------------------------------|\n",
    "| Q-E      | (input flow to plant)                                                |\n",
    "| ZN-E     | (input Zinc to plant)                                                |\n",
    "| PH-E     | (input pH to plant)                                                  |\n",
    "| DBO-E    | (input Biological demand of oxygen to plant)                         |\n",
    "| DQO-E    | (input chemical demand of oxygen to plant)                           |\n",
    "| SS-E     | (input suspended solids to plant)                                    |\n",
    "| SSV-E    | (input volatile supended solids to plant)                            |\n",
    "| SED-E    | (input sediments to plant)                                           |\n",
    "| COND-E   | (input conductivity to plant)                                        |\n",
    "| PH-P     | (input pH to primary settler)                                        |\n",
    "| DBO-P    | (input Biological demand of oxygen to primary settler)               |\n",
    "| SS-P     | (input suspended solids to primary settler)                          |\n",
    "| SSV-P    | (input volatile supended solids to primary settler)                  |\n",
    "| SED-P    | (input sediments to primary settler)                                 |\n",
    "| COND-P   | (input conductivity to primary settler)                              |\n",
    "| PH-D     | (input pH to secondary settler)                                      |\n",
    "| DBO-D    | (input Biological demand of oxygen to secondary settler)             |\n",
    "| DQO-D    | (input chemical demand of oxygen to secondary settler)               |\n",
    "| SS-D     | (input suspended solids to secondary settler)                        |\n",
    "| SSV-D    | (input volatile supended solids to secondary settler)                |\n",
    "| SED-D    | (input sediments to secondary settler)                               |\n",
    "| COND-D   | (input conductivity to secondary settler)                            |\n",
    "| PH-S     | (output pH)                                                          |\n",
    "| DBO-S    | (output Biological demand of oxygen)                                 |\n",
    "| DQO-S    | (output chemical demand of oxygen)                                   |\n",
    "| SS-S     | (output suspended solids)                                            |\n",
    "| SSV-S    | (output volatile supended solids)                                    |\n",
    "| SED-S    | (output sediments)                                                   |\n",
    "| COND-S   | (output conductivity)                                                |\n",
    "| RD-DBO-P | (performance input Biological demand of oxygen in primary settler)   |\n",
    "| RD-SS-P  | (performance input suspended solids to primary settler)              |\n",
    "| RD-SED-P | (performance input sediments to primary settler)                     |\n",
    "| RD-DBO-S | (performance input Biological demand of oxygen to secondary settler) |\n",
    "| RD-DQO-S | (performance input chemical demand of oxygen to secondary settler)   |\n",
    "| RD-DBO-G | (global performance input Biological demand of oxygen)               |\n",
    "| RD-DQO-G | (global performance input chemical demand of oxygen)                 |\n",
    "| RD-SS-G  | (global performance input suspended solids)                          |\n",
    "| RD-SED-G | (global performance input sediments)                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"anomaly_water_clean.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## understand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the timestamp format and frequency\n",
    "print(df['Date'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type of timestamp column for plotting\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "# plot the data\n",
    "df.plot(x='Date', y='Q-E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "We group together the usual combination of features. The points that are far from the cluster are points with unusual combinations of features.We consider those points as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take useful feature and standardize them\n",
    "data = df.drop(['Date'],axis=1)\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I choose 2 centroids arbitrarily and add these data to the central dataframe\n",
    "n_clust = 2\n",
    "kmeans = KMeans(n_clust).fit(data)\n",
    "scores = kmeans.score(data)\n",
    "df['cluster'] = kmeans.predict(data)\n",
    "\n",
    "#to visualize we must reduce to 2 principle components\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data)\n",
    "# standardize these 2 new features\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data_pca)\n",
    "data_pca = pd.DataFrame(np_scaled)\n",
    "\n",
    "df['principal_feature1'] = data_pca[0]\n",
    "df['principal_feature2'] = data_pca[1]\n",
    "df['cluster'].value_counts()\n",
    "df = df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the different clusters with the 2 main features)\n",
    "colors = {0:'red', 1:'blue', 2:'green', 3:'pink', 4:'black', 5:'orange', 6:'cyan', 7:'yellow', 8:'brown', 9:'purple', 10:'white', 11: 'grey', 12:'lightblue', 13:'lightgreen', 14: 'darkgrey'}\n",
    "plt.scatter(df['principal_feature1'], df['principal_feature2'], c=df[\"cluster\"].apply(lambda x: colors[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to calcuate distance to cluster center\n",
    "def getDistanceByPoint(data, model):\n",
    "    distance = pd.Series()\n",
    "    for i in range(0,len(data)):\n",
    "        Xa = np.array(data.loc[i])\n",
    "        Xb = model.cluster_centers_[model.labels_[i]-1]\n",
    "        distance.at[i] = np.linalg.norm(Xa-Xb)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distance between each point and its nearest centroid. The biggest distances are considered as anomaly\n",
    "distance = getDistanceByPoint(data, kmeans)\n",
    "df['distance'] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the fraction of point to classify as outliers\n",
    "outliers_fraction = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anomaly21 contain the anomaly result of cluster method (0:normal, 1:anomaly) \n",
    "distance = getDistanceByPoint(data, kmeans)\n",
    "number_of_outliers = int(outliers_fraction*len(distance))\n",
    "threshold = distance.nlargest(number_of_outliers).min()\n",
    "# anomaly21 contain the anomaly result of method 2.1 Cluster (0:normal, 1:anomaly) \n",
    "df['anomaly21'] = (distance >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation of anomaly with cluster view\n",
    "plt.scatter(df['principal_feature1'], df['principal_feature2'], c=df[\"anomaly21\"].apply(lambda x: colors[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization through time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a few plots of the data through time. You can plot the raw data, and also the principle components which summarize the data. On these plots, add lines or points to show where the anomlies occur in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
