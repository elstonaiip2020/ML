{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains information collected from 54 Mica2Dot sensors deployed in the Intel Berkeley Research lab between February 28th and April 5th, 2004.  \n",
    "\n",
    "Mica2Dot sensors with weather boards collected timestamped topology information, along with humidity, temperature, light and voltage values once every 31 seconds. 54 sensors were distributed throughout the laboratory. We will only look at the data for sensor 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='layout.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "df = pd.read_csv('input.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MotelID is the sensor location number, and epoch is a monotonically increasing time counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the Date and Time columns to create a datetime/timestamp column\n",
    "df['datetime'] = df['Date']+' '+df['Time']\n",
    "df['datetime'] =pd.to_datetime(df['datetime'])\n",
    "\n",
    "#filter dates\n",
    "df = df[(df.datetime < pd.Timestamp(datetime.date(year=2004,month=3,day=23)))]\n",
    "\n",
    "df = df.sort_values(by=['datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the non-required columns from the data\n",
    "df=df.drop('Date',axis=1)\n",
    "df=df.drop('Time',axis=1)\n",
    "df=df.drop('Epoch',axis=1)\n",
    "df=df.drop('MoteID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data of missing values\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling median outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the constants you need\n",
    "consistency_const = 1.4826\n",
    "thresh = 3\n",
    "\n",
    "#rolling median calculation\n",
    "df['median_Humidity'] = df.Humidity.rolling(480,center=True).median()\n",
    "\n",
    "#rolling MAD calculation\n",
    "df['median_Humidity_diff'] = abs(df.Humidity-df.median_Humidity)\n",
    "df['median_Humidity_mad'] = df.median_Humidity_diff.rolling(480,center=True).median()\n",
    "\n",
    "#rolling modified z-score calculation\n",
    "df['rolling_z_score'] = pd.to_numeric((df.median_Humidity_diff /(df.median_Humidity_mad*consistency_const)) > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[df.rolling_z_score == 0]\n",
    "anomaly = df[df.rolling_z_score == 1]\n",
    "\n",
    "#normal data as green points\n",
    "plt.plot_date(normal.datetime, normal.Humidity, color='green',markersize=0.5)\n",
    "#anomalies as red points\n",
    "plt.plot_date(anomaly.datetime, anomaly.Humidity, color='red',markersize=1)\n",
    "#rolling median as blue line\n",
    "plt.plot_date(df['datetime'],df['median_Humidity'], color='blue',linestyle='solid', marker='None')\n",
    "# You may get a futurewarning about the date conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it is not a surprise that these values are anomalous. They probably indicate sensor malfunction. Humidity can only range from 0 - 100. So lets filter these anomalies out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Humidity <100]\n",
    "normal = df[df.rolling_z_score == 0]\n",
    "anomaly = df[df.rolling_z_score == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot_date(normal.datetime, normal.Humidity, color='green',markersize=0.5)\n",
    "plt.plot_date(anomaly.datetime, anomaly.Humidity, color='red',markersize=1)\n",
    "plt.plot_date(df['datetime'],df['median_Humidity'], color='blue',linestyle='solid', marker='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks nice. Big drops or spikes in humidity are flagged as anomalies. Perhaps we would want to use this to inform our cooling or heating systems to response and adjust the climate accordingly. Let's look at a two day period in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot_date(normal.datetime, normal.Humidity, color='green',markersize=0.5)\n",
    "plt.plot_date(anomaly.datetime, anomaly.Humidity, color='red',markersize=1)\n",
    "plt.plot_date(df['datetime'],df['median_Humidity'], color='blue',linestyle='solid', marker='None')\n",
    "\n",
    "xmin = datetime.date(year=2004,month=3,day=8)\n",
    "xmax = datetime.date(year=2004,month=3,day=9)\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(30,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sudden drop near the beggining is flagged as anomalous. But smaller drops near the begginging are also flagged. Why is this? Well remember anomalies are defined relative the the variabilty around that time (using our moving MAD). Because variabilty at the start of this period is low, small changes are flagged as anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
